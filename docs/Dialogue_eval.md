对话交互能力评估基准

1.简介

构建了真实场景测试集，基于84条实际患者病历构建，并开发配套医患对话模拟框架。为了全面评估模型模拟对话的能力，使用DeepSeek-V3等第三方模型对医生的模拟对话进行多维度评分，并建立了相应的评分体系。本评分体系从临床信息收集、沟通技巧和诊断质量三个核心维度展开，并结合对话轮数的效率进行加权计算。

2.使用方法

```
python dialogue_eval.py --input input.xlsx  --api_key sk-xxxxx --url https://api.deepseek.com/v1 --model deepseek-chat
```

注：此处输入文件为由模型生成的医患模拟对话。该对话生成依赖于我们的批量测试打标工具，打标工具将在后续开放，敬请期待。

运行过程中会输出针对每句话的打分结果及依据，运行结束后生成总结，格式如下：



=== 问诊质量分析报告 ===
     基础平均分  加权平均分  达标率  平均轮数
复杂度
2     82.0   75.6  100.0%   5.0

评分说明:
- 加权公式: 最终得分 = 基础分×0.8 + 轮次达标×0.2
- 所有工作表的加权平均分: 75.60
- 报告已保存到: 问诊质量评估报告_20250409_041311.xlsx